{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcW8wHErC2pMVw464XUgvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flowers-huang/cs325b-wildfire/blob/main/cs325b_batch_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up Bullshit"
      ],
      "metadata": {
        "id": "xPyy5IunkfFY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2ip3rt2kQC_",
        "outputId": "ee98cc26-af74-44a3-ae65-f5b5d70a1d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2023.7.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.15.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray) (1.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray) (23.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.5)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2023.3.post1)\n",
            "Installing collected packages: snuggs, affine, rasterio, rioxarray\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.9 rioxarray-0.15.0 snuggs-1.4.7\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.7.0\n",
            "Collecting xbatcher\n",
            "  Downloading xbatcher-0.3.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from xbatcher) (2023.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xbatcher) (1.23.5)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from xbatcher) (2023.7.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (23.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask->xbatcher) (6.8.0)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray->xbatcher) (1.5.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask->xbatcher) (3.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray->xbatcher) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray->xbatcher) (2023.3.post1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask->xbatcher) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.4->xarray->xbatcher) (1.16.0)\n",
            "Installing collected packages: xbatcher\n",
            "Successfully installed xbatcher-0.3.0\n",
            "Collecting pystac\n",
            "  Downloading pystac-1.8.4-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting planetary_computer\n",
            "  Downloading planetary_computer-1.0.0-py3-none-any.whl (14 kB)\n",
            "Collecting zen3geo\n",
            "  Downloading zen3geo-0.6.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from pystac) (2.8.2)\n",
            "Requirement already satisfied: click>=7.1 in /usr/local/lib/python3.10/dist-packages (from planetary_computer) (8.1.7)\n",
            "Requirement already satisfied: pydantic>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from planetary_computer) (1.10.13)\n",
            "Collecting pystac-client>=0.2.0 (from planetary_computer)\n",
            "  Downloading pystac_client-0.7.5-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pytz>=2020.5 in /usr/local/lib/python3.10/dist-packages (from planetary_computer) (2023.3.post1)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from planetary_computer) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from planetary_computer) (23.2)\n",
            "Collecting python-dotenv (from planetary_computer)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: rioxarray>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from zen3geo) (0.15.0)\n",
            "Requirement already satisfied: torchdata>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from zen3geo) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.7.3->planetary_computer) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->pystac) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->planetary_computer) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->planetary_computer) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->planetary_computer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->planetary_computer) (2023.7.22)\n",
            "Requirement already satisfied: rasterio>=1.2 in /usr/local/lib/python3.10/dist-packages (from rioxarray>=0.10.0->zen3geo) (1.3.9)\n",
            "Requirement already satisfied: xarray>=0.17 in /usr/local/lib/python3.10/dist-packages (from rioxarray>=0.10.0->zen3geo) (2023.7.0)\n",
            "Requirement already satisfied: pyproj>=2.2 in /usr/local/lib/python3.10/dist-packages (from rioxarray>=0.10.0->zen3geo) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from rioxarray>=0.10.0->zen3geo) (1.23.5)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.4.0->zen3geo) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.4.0->zen3geo) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.4.0->zen3geo) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.4.0->zen3geo) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.4.0->zen3geo) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.4.0->zen3geo) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.4.0->zen3geo) (2.1.0)\n",
            "Requirement already satisfied: jsonschema~=4.18 in /usr/local/lib/python3.10/dist-packages (from pystac) (4.19.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->rioxarray>=0.10.0->zen3geo) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->rioxarray>=0.10.0->zen3geo) (23.1.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->rioxarray>=0.10.0->zen3geo) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->rioxarray>=0.10.0->zen3geo) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->rioxarray>=0.10.0->zen3geo) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->rioxarray>=0.10.0->zen3geo) (67.7.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray>=0.17->rioxarray>=0.10.0->zen3geo) (1.5.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema~=4.18->pystac) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema~=4.18->pystac) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema~=4.18->pystac) (0.10.6)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio>=1.2->rioxarray>=0.10.0->zen3geo) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata>=0.4.0->zen3geo) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata>=0.4.0->zen3geo) (1.3.0)\n",
            "Installing collected packages: python-dotenv, pystac, zen3geo, pystac-client, planetary_computer\n",
            "Successfully installed planetary_computer-1.0.0 pystac-1.8.4 pystac-client-0.7.5 python-dotenv-1.0.0 zen3geo-0.6.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio xarray geopandas matplotlib rioxarray\n",
        "!pip install einops scikit-learn\n",
        "!pip install xbatcher\n",
        "!pip install pystac planetary_computer zen3geo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import rioxarray\n",
        "import xarray as xr\n",
        "import geopandas as gpd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "import os\n",
        "import dask\n",
        "import rioxarray\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "from itertools import combinations\n",
        "from dask.diagnostics import ProgressBar"
      ],
      "metadata": {
        "id": "uw2bVB-hGlG6"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth, drive\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!wget https://github.com/GoogleCloudPlatform/gcsfuse/releases/download/v1.2.0/gcsfuse_1.2.0_amd64.deb\n",
        "!sudo dpkg -i gcsfuse_1.2.0_amd64.deb\n",
        "\n",
        "# Create a directory to mount\n",
        "!mkdir \"/content/drive/MyDrive/burned_area\"\n",
        "\n",
        "!gcsfuse --implicit-dirs cs325b-burned-area \"/content/drive/MyDrive/burned_area\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfb9TxDKkbhk",
        "outputId": "9594f034-0f03-4f4e-c065-9f289ab8d53c"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "--2023-10-23 04:08:19--  https://github.com/GoogleCloudPlatform/gcsfuse/releases/download/v1.2.0/gcsfuse_1.2.0_amd64.deb\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/30325550/e8d09242-0eb6-4233-9d29-605ebcf8bc63?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231023T040718Z&X-Amz-Expires=300&X-Amz-Signature=05791fcda35ca8023f7e14e5baa06057cd83ccf5519300fbff9e8aa5783c7b59&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=30325550&response-content-disposition=attachment%3B%20filename%3Dgcsfuse_1.2.0_amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-10-23 04:08:19--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/30325550/e8d09242-0eb6-4233-9d29-605ebcf8bc63?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231023T040718Z&X-Amz-Expires=300&X-Amz-Signature=05791fcda35ca8023f7e14e5baa06057cd83ccf5519300fbff9e8aa5783c7b59&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=30325550&response-content-disposition=attachment%3B%20filename%3Dgcsfuse_1.2.0_amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5557872 (5.3M) [application/octet-stream]\n",
            "Saving to: ‘gcsfuse_1.2.0_amd64.deb.1’\n",
            "\n",
            "gcsfuse_1.2.0_amd64 100%[===================>]   5.30M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-23 04:08:19 (91.4 MB/s) - ‘gcsfuse_1.2.0_amd64.deb.1’ saved [5557872/5557872]\n",
            "\n",
            "(Reading database ... 120881 files and directories currently installed.)\n",
            "Preparing to unpack gcsfuse_1.2.0_amd64.deb ...\n",
            "Unpacking gcsfuse (1.2.0) over (1.2.0) ...\n",
            "Setting up gcsfuse (1.2.0) ...\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/burned_area’: File exists\n",
            "{\"time\":\"23/10/2023 04:08:22.034541\",\"severity\":\"INFO\",\"msg\":\"Start gcsfuse/1.2.0 (Go version go1.21.0) for app \\\"\\\" using mount point: /content/drive/MyDrive/burned_area\\n\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NIkjntOukyaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "url = 'https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/MTBS_Fire/data/composite_data/burned_area_extent_shapefile/mtbs_perimeter_data.zip'\n",
        "filename = url.split(\"/\")[-1]\n",
        "directory = '/content/mtbs_perims_DD'\n",
        "\n",
        "# !mkdir \"/content/drive/MyDrive/burned_area/mtbs_perims_DD\"\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Download the zip file\n",
        "response = requests.get(url)\n",
        "filepath = os.path.join(directory, filename)\n",
        "with open(filepath, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory)\n",
        "\n",
        "# Remove the zip file if you want\n",
        "os.remove(filepath)"
      ],
      "metadata": {
        "id": "VwA9Swltk1mz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import rioxarray\n",
        "import xarray as xr\n",
        "import geopandas as gpd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pystac\n",
        "import planetary_computer\n",
        "\n",
        "import torch\n",
        "import torchdata\n",
        "import zen3geo\n",
        "\n",
        "\n",
        "# from src.dnbr import apply_bit_mask_group, apply_bitmask"
      ],
      "metadata": {
        "id": "OI3dVX3wk5fx"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mask calculation functions and whatnot"
      ],
      "metadata": {
        "id": "qzS1XMUlltUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "import os\n",
        "import dask\n",
        "import rioxarray\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "from itertools import combinations\n",
        "from dask.diagnostics import ProgressBar\n",
        "\n",
        "\n",
        "def apply_bitmask(arr) -> xr.DataArray or np.array:\n",
        "    \"\"\"Apply QA pixel bit mask for each array depending on platform\"\"\"\n",
        "\n",
        "    unique_platform = np.unique(arr.platform.to_numpy())\n",
        "\n",
        "    if [\"landsat-8\", \"landsat-9\"] in unique_platform:\n",
        "        mask_bitfields = [1, 2, 3, 4]  # dilated cloud, cirrus, cloud, cloud shadow\n",
        "    elif [\"landsat-4\", \"landsat-5\", \"landsat-7\"] in unique_platform:\n",
        "        mask_bitfields = [1, 3, 4, 5]  # dilated cloud, cirrus, cloud, cloud shadow\n",
        "    elif [\"landsat-4\", \"landsat-5\"] in unique_platform:\n",
        "        mask_bitfields = [1, 3, 4, 5]  # dilated cloud, cirrus, cloud, cloud shadow\n",
        "    else:\n",
        "        raise ValueError(f\"No bit mask defined for {arr.platform.to_numpy()}\")\n",
        "\n",
        "    bitmask = 0\n",
        "    for field in mask_bitfields:\n",
        "        bitmask |= 1 << field\n",
        "\n",
        "    qa = arr.sel(band=\"qa_pixel\").astype(\"uint16\")\n",
        "    bad = qa & bitmask  # just look at those 4 bits\n",
        "\n",
        "    arr = arr.where(bad == 0)\n",
        "\n",
        "    return arr\n",
        "\n",
        "\n",
        "def calculate_nbr(data):\n",
        "    \"\"\"Calculate NBR in xarray DataArray\n",
        "\n",
        "    Calculate the Normalized Burn Ratio for a DataArray with Landsat data. This\n",
        "    function uses the NBR standard formula: (NIR-SWIR)/(NIR+SWIR).\n",
        "\n",
        "    Args:\n",
        "        - data (xr.DataArray): A data array with the \"nir08\" and the \"swir16\"\n",
        "          bands.\n",
        "\n",
        "    Returns:\n",
        "        xr.DataArray\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate NBR manually using the normal formula\n",
        "    nbr_manual = (\n",
        "        data.sel(band=\"nir08\").squeeze() - data.sel(band=\"swir16\").squeeze()\n",
        "    ) / (data.sel(band=\"nir08\").squeeze() + data.sel(band=\"swir16\").squeeze())\n",
        "    # print((data.sel(band=\"nir08\").squeeze() + data.sel(band=\"swir16\").squeeze()).compute())\n",
        "\n",
        "    return nbr_manual\n",
        "\n",
        "\n",
        "@dask.delayed\n",
        "def apply_bit_mask_group(arr):\n",
        "    \"\"\"Apply QA mask to array across different platforms\n",
        "\n",
        "    Apply the QA mask on xarray object using the platform variable. If the\n",
        "    coordinate is not available, then an error will be raised! If the platform\n",
        "    value is unique, then is only applied to the unique platform.\n",
        "\n",
        "    Args:\n",
        "        - arr (xr.Dataset or xr.DataArray)\n",
        "\n",
        "    Returns:\n",
        "        xr.Dataset or xr.DataArray\n",
        "    \"\"\"\n",
        "\n",
        "    # Apply QA bitmask\n",
        "    try:\n",
        "        if len(temp_data['platform'].dims) == 0:\n",
        "          arr = apply_bitmask(arr)\n",
        "        else:\n",
        "          arr = arr.groupby(\"platform\").map(apply_bitmask)\n",
        "    except TypeError or IndexError as e:\n",
        "        print(f\"Exception: {e}. Maybe platform length is zero: {arr.platform.values}\")\n",
        "        arr = apply_bitmask(arr)\n",
        "\n",
        "    return arr\n",
        "\n",
        "\n",
        "def calculate_dnbr(\n",
        "    pre_array,\n",
        "    post_array,\n",
        "    geometry,\n",
        "    buffer_offset_size=180,\n",
        "    apply_qa_bitmask=True,\n",
        "    event_id=None,\n",
        "    save=None,\n",
        ") -> xr.DataArray:\n",
        "    \"\"\"Calculate dNBR for a specific even across timeline\n",
        "\n",
        "    Following Parks (2019), we calculate the dNBR using two sets of images: one\n",
        "    pre- and post-event. We calculate the NBR using the mean composite of both\n",
        "    sets and then subtract the pre values from the post period. Since we want to\n",
        "    compare events, we calculate an offset using the buffer. Then our dNBR for\n",
        "    each pixel is:\n",
        "\n",
        "        \\[\n",
        "        \\DeltaNBR_{i} = NBR_{i, t=1} - NBR_{i, t=0} - NBR_{offset}\n",
        "        \\]\n",
        "\n",
        "    Args:\n",
        "        - pre_array (str): path to pre-array path for the event. If event_id is\n",
        "          passed, then only the root path will be used.\n",
        "        - post_array (str): path to post-array for the same event. If event_id\n",
        "          is passed, then only the root path will be used\n",
        "        - geometry (gpd.GeoDataFrame): Spatial dataframe object with event data.\n",
        "          The function expect that event_id is identical.\n",
        "        - buffer_offset_size (int): Buffer distance to build offset value. If\n",
        "          None, then no offset will be calculated.\n",
        "        - apply_qa_bitmask (bool): If `True` apply the bitmask and remove all\n",
        "          bad pixels following the QA flags\n",
        "        - event_id (str): Event ID to find images in pre and post imagery paths\n",
        "          and in geometry.\n",
        "        - save (str): A path to save the restulting array. If `None`, then it\n",
        "          won't save it.\n",
        "\n",
        "    Returns:\n",
        "        xr.DataArray\n",
        "    \"\"\"\n",
        "\n",
        "    # Keep this format for all dates\n",
        "    format_date = \"%Y-%m-%d\"\n",
        "\n",
        "    # Build paths\n",
        "    if event_id is not None:\n",
        "        pre_array_path = os.path.join(pre_array, f\"{event_id}.nc4\")\n",
        "        post_array_path = os.path.join(post_array, f\"{event_id}.nc4\")\n",
        "    else:\n",
        "        pre_array_path, post_array_path = (pre_array, post_array)\n",
        "\n",
        "    # Open files and prepare for QA cleaning\n",
        "    pre_data = xr.open_mfdataset(pre_array_path)\n",
        "    post_data = xr.open_mfdataset(post_array_path)\n",
        "\n",
        "    if apply_qa_bitmask:\n",
        "        pre_data = apply_bit_mask_group(pre_data)\n",
        "        post_data = apply_bit_mask_group(post_data)\n",
        "\n",
        "    # Open datasets and calculate mean\n",
        "    pre_data = pre_data.mean(dim=\"time\").rio.write_crs(\"4326\").to_array().squeeze()\n",
        "    # Notice that we use interp here to account to possible differences in the\n",
        "    # coordinates within pre and post. This is similar to a bilinear\n",
        "    # interpolation where\n",
        "    post_data = (\n",
        "        post_data.mean(dim=\"time\")\n",
        "        .rio.write_crs(\"4326\")\n",
        "        .to_array()\n",
        "        .squeeze()\n",
        "    )\n",
        "\n",
        "    pres_data = pre_data.interp_like(post_data, method=\"linear\", kwargs={\"fill_value\": \"extrapolate\"})\n",
        "\n",
        "    # print(post_data.compute())\n",
        "\n",
        "    # Calculate offset\n",
        "    if False: #buffer_offset_size is not None:\n",
        "        # Check projection\n",
        "        if not geometry.crs.is_projected:\n",
        "            raise TypeError(f\"{geometry.crs} no good for these calculations\")\n",
        "\n",
        "        try:\n",
        "            geom_event = geometry[geometry.Event_ID == event_id]\n",
        "            buffer = geom_event.buffer(buffer_offset_size)\n",
        "\n",
        "            # Calculate difference and project back to lat/lon\n",
        "            offset = buffer.difference(geom_event)\n",
        "            offset_planar = offset.to_crs(4326).geometry.values\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(\n",
        "                f\"Exception {e}: Cannot find event id columnd maybe? {geometry.columns}\"\n",
        "            )\n",
        "\n",
        "        # Caclulate off-set in data\n",
        "        pre_data_ring = pre_data.rio.clip(\n",
        "            offset_planar, crs=4326, drop=False, invert=False\n",
        "        )\n",
        "        post_data_ring = post_data.rio.clip(\n",
        "            offset_planar, crs=4326, drop=False, invert=False\n",
        "        )\n",
        "\n",
        "        # Calculate NBR\n",
        "        pre_nbr_ring = calculate_nbr(pre_data_ring)\n",
        "        post_nbr_ring = calculate_nbr(post_data_ring)\n",
        "\n",
        "        dnbr_ring = (pre_nbr_ring - post_nbr_ring).mean().squeeze()\n",
        "\n",
        "    else:\n",
        "        dnbr_ring = 0\n",
        "\n",
        "    # Calculate NBR for both periods\n",
        "    pre_nbr = calculate_nbr(pre_data)\n",
        "    post_nbr = calculate_nbr(post_data)\n",
        "\n",
        "    # Calculate dNBR for all the pixels\n",
        "    dnbr = (pre_nbr - post_nbr) - dnbr_ring\n",
        "\n",
        "    if save is not None:\n",
        "        dnbr.rio.to_raster(save, tiled=True, windowed=True)\n",
        "\n",
        "    return dnbr.compute()"
      ],
      "metadata": {
        "id": "fPrya6Vyls15"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kfGWoz7HlxwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = Path(\"/content/drive/MyDrive/burned_area/\")\n",
        "pre_root_dir = root_dir / \"pre-images\"\n",
        "post_root_dir = root_dir / \"post-images\"\n",
        "impost_root_dir = root_dir / \"inmediate-post-fire-images\"\n",
        "processed_root_dir = root_dir / \"processed_geotiff\"\n",
        "# root_dir = Path(\"/content/data/post-images\")\n",
        "files_pre = set(os.listdir(pre_root_dir))\n",
        "files_post = set(os.listdir(post_root_dir))\n",
        "files_impost = set(os.listdir(impost_root_dir))\n",
        "files_proc = set(os.listdir(processed_root_dir))\n",
        "\n",
        "files_pre = {Path(f).stem: pre_root_dir / f for f in files_pre}\n",
        "files_post = {Path(f).stem: post_root_dir / f for f in files_post}\n",
        "files_impost = {Path(f).stem: impost_root_dir / f for f in files_impost}\n",
        "files_proc = {Path(f).stem: processed_root_dir / f for f in files_proc}\n",
        "\n",
        "shared_files = list(files_pre.keys() & files_post.keys() & files_impost.keys() & files_proc.keys())\n",
        "\n",
        "len(shared_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAtGd1-ql1kY",
        "outputId": "f5ccb2db-ca37-42f8-ccef-0fecc16f6fea"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1570"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "UYOJXSBXOxyI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files_pre, files_post, labels):\n",
        "      self.data = []\n",
        "      self.labels = labels\n",
        "      self.label_count = [0, 0]\n",
        "\n",
        "      for path_name in files_pre:\n",
        "          #pre_root_dir = root_dir / \"pre-images\"\n",
        "          self.data.append([pre_root_dir / (path_name + \".nc4\"), \"pre\"])\n",
        "          self.label_count[0] += 1\n",
        "\n",
        "      for path_name in files_post:\n",
        "          self.data.append([post_root_dir / (path_name + \".nc4\"), \"post\"])\n",
        "          self.label_count[1] += 1\n",
        "\n",
        "      print(\"Collected\", self.label_count, \"images\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      data = self.data[idx][0]\n",
        "      label = self.data[idx][1]\n",
        "\n",
        "      #print(label, idx, data)\n",
        "\n",
        "      ds = (\n",
        "          xr.open_dataset(data)\n",
        "          .to_array() # transform to an array rather than the xr.Dataset\n",
        "          .squeeze()  # just like in numpy, remove all singletons\n",
        "      )\n",
        "\n",
        "      #print(ds)\n",
        "\n",
        "      fixed_banding = ds.median(dim=\"time\").sel(band=[\"red\", \"green\", \"blue\", 'nir08', 'swir16', 'qa_pixel']).to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "      #sample = {\"image\": ds.to_numpy(), \"class\": label}\n",
        "      return fixed_banding, label"
      ],
      "metadata": {
        "id": "Zw-wQIndGUzl"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dataset obj\n",
        "labels = [\"pre\", \"post\"]\n",
        "image_dataset = CustomDataset(files_pre, files_post, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwNQIIVhYZPW",
        "outputId": "22d4ad33-9481-4775-dd87-298148fd104a"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected [1651, 1714] images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a new fucking collating function\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    '''\n",
        "    # modified from https://zen3geo.readthedocs.io/en/v0.2.0/chipping.html#pool-chips-into-mini-batches\n",
        "    # does not work\n",
        "\n",
        "    tensors = [\n",
        "        torch.as_tensor(\n",
        "            #data=sample[0].data_vars.get(key=\"id\").data.astype(\"int16\"),\n",
        "            data=sample[0].to_array,\n",
        "        )\n",
        "        for sample in samples\n",
        "    ]\n",
        "    return torch.stack(tensors=tensors)\n",
        "    '''\n",
        "\n",
        "    #for sample in samples:\n",
        "    #  print(sample[0].data_vars)\n",
        "    #  print(sample[0].median(dim=\"time\").sel(band=[\"red\", \"green\", \"blue\"]))\n",
        "\n",
        "    zipped = zip(batch)\n",
        "    return list(zipped)\n",
        "\n"
      ],
      "metadata": {
        "id": "cZsErYrxxQQ7"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generates a new dataloader object\n",
        "image_dl = DataLoader(image_dataset, collate_fn=collate_fn, batch_size = 64, shuffle=True)\n",
        "#image_dl = DataLoader(image_dataset, batch_size = 4, shuffle=True)"
      ],
      "metadata": {
        "id": "Q973AT8dO35b"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 3\n",
        "\n",
        "for (idx, batch) in enumerate(image_dl):\n",
        "  print(idx)\n",
        "\n",
        "  if idx == i:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCRN_0Dcimzc",
        "outputId": "9268b2f7-6cd5-4bf8-e68a-bb867c60bbb1"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "    print(\"\\n==============================\\n\")\n",
        "    print(\"Epoch = \" + str(epoch))\n",
        "    for (idx, batch) in enumerate(image_dl):\n",
        "      print(\"\\nBatch = \" + str(idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "ihDQYiduPRbl",
        "outputId": "6067b06f-3f97-4b43-af25-3c0ba1e9a962"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "\n",
            "Epoch = 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-256-abb2421d4d41>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n==============================\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBatch = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-241-22ea8dcbdef2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m       ds = (\n\u001b[1;32m     31\u001b[0m           \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# transform to an array rather than the xr.Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# just like in numpy, remove all singletons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mto_array\u001b[0;34m(self, dim, name)\u001b[0m\n\u001b[1;32m   6585\u001b[0m         \u001b[0mdata_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6586\u001b[0m         \u001b[0mbroadcast_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6587\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduck_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6589\u001b[0m         \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6585\u001b[0m         \u001b[0mdata_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6586\u001b[0m         \u001b[0mbroadcast_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6587\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduck_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6589\u001b[0m         \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplicitlyIndexed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mget_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36m_ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ensure_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mget_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mget_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;31m# self.array[self.key] is now a numpy array when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# self.array is a BackendArray subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/h5netcdf_.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         return indexing.explicit_indexing_adapter(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexingSupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTER_1VECTOR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \"\"\"\n\u001b[1;32m    857\u001b[0m     \u001b[0mraw_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompose_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing_support\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_indexing_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnumpy_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# index the loaded np.ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/h5netcdf_.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5netcdf/core.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    345\u001b[0m             )[key]\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h5ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_read_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Fall back to Python read pathway below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Might be worth looking into tensorflow later: https://github.com/ThomasMGeo/netCDF2ML/blob/main/noah_demo.ipynb is a code snippet that works apparently but honestly fuck tensorflow bc we usually use pytorch now? if all else fails we can do this"
      ],
      "metadata": {
        "id": "70s6hApU_fBA"
      }
    }
  ]
}